# [[MIT] 데이터 사이언스 기초](https://www.edwith.org/datascience/lecture/33888/)
Today I Learned

## Chapter 1. Introduction and Optimization Problems
### 계산모델 (Computation Model)
- 이제까지 일어났던 무언가를 이해하거라 매일 보는 현상들을 설명하는 모델
- 아직 일어나지 않은 미래를 예측할 수 있게 해주는 모델
- 예) 날씨 변화 모델 : 천년 동안 날씨가 어떻게 변했는지에 대한 모델과 미래에 어떻게 될지 예측하는 모델을 만들 수 있음

### 최적화 모델(Optimization Model)
- 제한 조건을 가지며 목적 함수를 최대화 또는 최소화하는 모델
- 냅색(배낭) 문제
  제한 조건 : 냅색 안에 들어갈 수 있는 양
  도둑이 가장 값비싼 물건을 훔쳐야 하는 최적화 문제
  연속 냅색 문제
    - 일부분만 가져갈 수 있는 문제(금괴가 아닌 금모래로 가져갈 수 있는 경우)
    - 탐욕 알고리즘으로도 풀 수 있고, 풀기 쉬운 편
  0/1 냅색 문제
    - 금괴를 가져가거나 아예 못 가져가는 경우
    - 한번 결정하면 그 결정이 다음 결정에 영향을 미침
    
### 최적화 문제를 푸는 방법
- 무차별 대입 알고리즘(Brute force algorithm)
    모든 경우의 수를 고려해 승자를 택하는 것
    그러나 실용적이지는 않다
- 탐욕 알고리즘 (Greedy algorithm)
    while kanpsack not full put 'best' available item in kanpsack
    여러 경우 중 하나를 결정할 때 그 순간 best 라고 생각되는 것을 선택해 나가는 방식
    가장 좋은 것 (best)의 의미는 정의에 따라 달라짐
    탐욕 알고리즘은 좋은 해를 구할수는 있어도 최적 해를 구할수는 없음
    
### 파이썬 람다 표현식
- 익명의 함수를 만들 때 사용
- (lambda 식별자 배열: 원하는 식)
- 이 파라미터들로 표현된 식을 계산하고 결과를 반환하는 함수를 만듬
- def 를 쓰는 대신에 인라인 함수로 정의

람다 함수에 대한 설명이 나와있는 문서
[점프 투 파이썬](https://wikidocs.net/64) 

## Chapter 2. Optimization Problems
### 탐욕 알고리즘(Greedy Algorithm)
결정할 때마다 그 순간에 최적이라고 생각되는 것을 선택해 나가는 방식으로 최종 답에 도달하는 방식
- 장점 : 구현하기 쉬움, 매우 빠름
- 단점 : 최적일 수도 있고 아닐수도 있는 해를 구함

### 무차별 대입 알고리즘(Brute Force Algorithm)
- 탐욕 알고리즘을 대체할 수 있는 알고리즘
- 항목의 조합 가능한 수를 열거한 후, 전체 합이 가중치를 넘어가는 것은 제거

### 동적 프로그래밍(Dynamic Programming)
- 복잡한 문제를 간단한 여러 개의 문제로 나누어 푸는 방법
- 최적 부분 구조 문제일 경우 풀 수 있는 방법
    - For x > 1, fib(x) = fib(x-1) + fib(x-2)
- 중복 부분 문제일 경우 풀 수 있는 방법
    - 최적 해를 구할 때 같은 문제를 여러 번 풀어야 하는 문제
    - fib(x)를 1번 계산하거나 여러 번 계산하는 경우
- 근사가 아닌 최적화 해법이 구해짐

## Chapter 3. Graph-theoretic Models
### 그래프(Graph)
- 그래프는 꼭짓점 혹은 노드로 이루저이고 이들은 간선 혹은 변으로 이루어짐
- 노드의 집합
    - 각 노드는 다른 노드와 관계된 정보를 담고있음
    - 예 ; 학생의 성적
- 간선, 변이
    - 노드의 쌍을 연결
    - 간선을 이용해 그래프를 만드는 2가지 방법: 무방향, 유향
- 사용 예시
    - 개체 사이의 관계 표시
        - 예 : 파리에서 런던으로 여행을 갈 때 노드는 각 도시 연결은 도시 사이 레일
- 유용한 이유
    - 세상에 존재하는 여러 관꼐는 그래프로 표현하기 적합
    - 컴퓨터 네트워크, 교통 네트워크, 금융 네트워크, 정치 네트워크, 범죄 네트워크, 사회 네트워크 등
- 그래프를 만드는 방법
    - 두 요소 사이에 연속된 간선이 있는지 확인
    - 최소 비용 혹은 최단 경로를 찾을 수 있는지 확인
    - 그래프 분할 문제로 접근
그래프 탐색
    - 한 노드에서 다른 노드로 가는 최단 경로를 구하는 방법은?
    - 최단 경로 : 시작점의 첫 간선 ~ 도착점의 마지막 간선
        - 일종의 사슬처럼 보임
    - 알고싶은 것 : 최소 단계 수
    - 1) 깊이 우선 탐색 (Depth-first Search)
        - 루트 노드에서 시작해 다음 분기로 넘어가기 전에 해당 분기를 모두 탐색하는 방법
        - 루프의 가능성이 있기 떄문에 경로를 기억해야 함
        - 이미 들렀던 노드는 가지 않음
            - 첫 간선을 따라가다 올바르게 왔는지 확인 올바르지 않으면 루프
            - 목표 노드에 도착하거나 선택지가 없어질 때까지 반복
        - 특징
            - 자기 자신을 호출하는 순환 알고리즘
            - 어떤 노드를 방문했는지를 반드시 확인
     
     [그래프 깊이 우선 탐색 ratsgo's blog](https://ratsgo.github.io/data%20structure&algorithm/2017/11/20/DFS/)            
     ```python     
    from pythonds.graphs import Graph
    class DFSGraph(Graph):
        def __init__(self):
            super().__init__()
            self.time = 0
            
        def dfs(self):
            # 모든 노드의 색상을 white, 부모노드 정보를 -1로 초기화
            for aVertex in self:
                aVertex.setColor('white')
                aVertex.setPred(-1)
            for aVertex in self:
                # 임의의 노드가 아직 방문하지 않은(white) 노드라면 해당 노드에 대해 dfsvisit 호출
                # dfsvisit은 더 이상 나아갈 엣지가 없을 떄까지 재귀적으로 수행, 수행 후에도 white인 노드가
                # 있으면 해당 노드를 시작노드로 해서 dfsvisit 반복 수행
                if aVertex.getColor() == 'white':
                    self.dfsvisit(aVertex)
        
        def dfsvisit(self, startVertex):
            # processing 이라는 의미로 시작노드의 색상을 gray로 변
              
     ```
     
    - 2) 너비 우선 탐색 (Breadth-first Search)
        - 루트 노드에서 시작해 인접한 노드를 먼저 탐색하는 방법
        - 특징
            - 루트 노드에서 목표 노드까지의 최단 거리를 보장
            

## Chapter 4. Stochastic Thinking
### 확률론적 사고(Stochastic Thinking)
- 세계를 본질적으로 예측가능할 수 없다고 취급하는 것이 나을 수 있음
    - 세상엔 불확실성(무작위성)이 너무 많아 이해하기 어려움
    - 무작위성을 위해 확률론적 사고를 할 필요성이 있음
    
- 확률에 대한 3가지 기본 사실
    - 확률은 항상 0 ~ 1
    - 분모 : 가능한 모든 사건의 수 분자 : 부분 집한인 관심을 갖는 사건
    - 어떤 사건이 일어날 확률이 p라면 일어나지 않을 확률은 1-p
    
- 중요한 법칙 (곱의 법칙)
    - 사건이 서로 독립적이라면 모든 사건이 일어날 확률은 각 사건이 일어날 확률을 곱한 것과 같음
    - A가 일어날 확률이 0.5고 B가 일어날 확률이 0.4라면 A,B가 이러날 확률은 0.2
    - 그러나 이런 법칙은 독립적인 경우에만 적용
    - 하나의 결과가 다른 결과에 영향을 주지 않는다면 두 사건은 독립적
    - 사람들은 자주 독립성이 없는 경우에도 독립적임을 가정하고 확률을 계산하니 주의가 필요

### 시뮬레이션 모델(Simulation Model)
- 시스템이 가능한 행동에 대한 정보를 제공하는 계산을 나타내는 프로그램
    - 시뮬레이션을 작성하고, 그 사건이 드물게 발생하면 추정된 확률을 믿기 전에 더 많은 시도를 하는 것이 좋음
        - 드물게 발생하는 사건의 좋은 추정을 얻기 위해선 많은 시도가 필요
        - 항상 실제 확률과 헷갈리지 않도록 추정된 확률이라는 것을 알고 있어야 함
- 시뮬레이션을 사용하는 이유는?
    - 복잡한 확률 계산을 하는 대신 확률적인 질문에 대한 답을 얻기 위해 시뮬레이션을 사용하는 주된 이유
- 초반에 본 최적화 모델(1~3강)과 다른 점
    - 최적화 모델은 규범적
    - 어떻게 배낭에서 최대의 가치를 얻는지
    - 어떠헥 A에서 B로 가는 최단 거리로 가는지
    - 반면 시뮬레이션 모델은
        - 이런 결과가 나타난다는 것을 말해줌
        - 어떻게 그 일을 일어나게 해주는지 말해주지 않음
        - 현실의 근사치일뿐임
        - 수학적으로 접근하기 힘든 문제를 풀 경우 시뮬레이션을 사용하면 유용
        - 다양한 조건을 쉽게 조절하면서 진행할 수 있기 떄문에 잘 사용함
        
- random.choice 함수
    - 실제로 무작위적이지 않음 의사 난수라는 것을 생성함 (pseudo random)
        - 연속된 수에서 한 숫자가 다음 숫자를 생성하는 알고리즘이 있음(seed)
        - 컴퓨터의 클럭을 가지고 읽음
        - random.seed 를 사용해 같은 시작점에 대해 같은 무작위적인 값을 얻음
    - 해당 원소 중 하나를 추출
    - p 파라미터에 확률값을 넣어서 사용할 수 있음
                  
    
## Chapter 5. Random Walks
### 무작위 행보(Random Walks)
- 많은 영역에서 중요
    - 주식 시장에서 가격의 움직임을 입증하는데 가장 좋은 모델
    - 현대의 많은 포트폴리오 분석이 기반을 두고 있음
    - 전파를 모델링할 때도 랜덤 워크를 사용, 열 전파나 분자의 전파
- 우리 주변의 세계를 이해하기 위해 시뮬레이션을 어떻게 사용할지에 대한 좋은 사례를 제공
- 추상적인 것들을 다루면서 프로그래밍과 소프트웨어 엔지니어링을 같이 진행
- 예시) 술 취한 사람의 걸음과 편향성을 가진 술 취한 사람의 걸음 차이를 파악

### 위생 검사 (Sanity Check)
- 시뮬레이션을 생성핧 땐 위생 검사가 필요
- 시뮬레이션이 실제로 말이 되는지 확인하는 과정
    - 의심을 가져야 함
    - 코드에 버그가 있을 수 있음!

### 정리
- 랜덤 워크를 하는 요점은 시뮬레이션 모델이 아닌 어떻게 만드는지에 관한 것
- 클래스를 정의하는 것부터 한번의 시도와 여러 번의 시도에 대응하는 함수를 만들고 결과를 보는 과정
- 시뮬레이션에 점진적 변화를 줘서 다른 문제를 조사할 수 있음
- 처음엔 간단한 시뮬레이션으로 시작해 잘 되지 않는 이유를 알고 Sanity check로 잘못된 것을 체크
- plot 스타일로 그래프를 그림

## Chapter 6. Monte Carlo Simulation
### 몬테 카를로 시뮬레이션(Monte Carlo Simulation)
- 추리통게학을 이용해 알 수 없는 값을 추정하는 방법
- 핵심 개념은 모집단
    - 모집단 : 가능한 예시들의 전체 집합
    - 모집단으로부터 적당한 부분 집합을 뽑음
        - 표본의 통계를 통해 모집단을 추론
        - 일반적으로 표본을 추출하면 그 표본이 모집단과 동일한 특성을 갖는 경향이 있음
        - 우리가 취할 수 있는 수많은 랜덤워크, 만개를 보지않고 100개 추출해서 평균 계산한 후 기대값 계산
        - 표본 추출이 무작위어야 함! 무작위로 뽑은 표본이 아니면 모집단과 같은 특성을 가질 것이라고 기대할 수 있는 근거가 없음

### 큰 수의 법칙 또는 베르누이의 법칙
- 실제 확률이 동일한 독립사건이 반복되면 실행 횟수가 무한대로 갈수록 p와 다른 결과가 나오는 횟수의 비율이 0으로 수렴
- 공정한 룰렛 휠을 무한번 돌리면 기댓값이 0이 됨

### 도박사의 오류
- 잘못된 결과의 오류
- 도박사의 오류에 의하면 사람들은 기대와 다른 이변이 일어나면 미래에 다시 정상으로 돌아올 것이라고 믿음
- 서로 영향을 끼치지 않는 일련의 확률적 사건들에서 상관 관계를 찾는 오류를 발생

### 평균으로의 회귀
- 부모가 둘 다 평균보다 키크면 자식이 부모보다 작은 가능성이 높다
- 역으로 부모가 평균보다 작으면 자식은 평균보다 클 가능성이 높다
- 도박사의 오류와 미묘하게 다름
- 극단적인 사건 다음에 오는 사건은 덜 극단적인 경향이 있다
- 공정 룰렛 휠을 10번 돌려 빨간색이 나온다면(극단적 사례) 10번에서는 빨간색이 10보다 적게 나온다는 개념. 덜 극단적인 사건이다
- 극단적인 결과보다는 20번 돌린 것의 평균 결과가 50% 빨간색이라는 평균값에 더 가까울 것
- 더 많은 표본을 취할수록 평균에 더 가까워짐

### 분산과 표준편차
- 기저 확률의 변이성에 따라 필요한 표본의 수가 달라짐
- 데이터의 변이성을 알기 위해 알아야 되는 개념 : 분산
    - 평균으로부터 모두의 거리를 구하여 단순히 다 더함
    - 마지막으로 집합의 크기(전체 항목) 개수로 나눔
    - 단지 항목의 개수가 많다는 이유로 분산이 높아지는 것을 막기 위해서, 항목의 개수로 정규화함
    - 제곱을 하는 이유 :
        - 차이가 양수든 음수든 상관이 없다는 것. 평균으로부터 어느 쪽에 있는지보다 근처에 있지 않다는 것이 중요함
        - 거리를 제곱해 이상치를 특별히 강조함(장점이자 단점)
- 표준편차
    - 분산의 제곱근
    - 표준편차 그 자체로는 의미없는 숫자
    - 항상 평균을 고렿애 생각해야 함
- 신뢰구간
    - 우리는 종종 평균만 가지고 예측하려고 함
    - 값을 모르는 매개변수를 설명할 때 기댓값과 같은 특정 값을 주는 것보다 신뢰 구간으로 표현하는 것이 좋음
    - 신뢰구간은 모르는 값이 포함될 가능서이 높은 구간과 그 구간에 존재할 확률을 알려줌
    - 결과가 -1%과 +1% 사이일 것이라 예측하고 전체 게임 중 95%는 이 예측이 맞을 것이라고 기대하는 것
- 신뢰 구간은 어떻게 계산할까?
    - 경험적인 규칙을 사용
    - 데이터를 얻어 평균을 찾고 표준편차를 계산하면 데이터의 58%는 평균값 앞뒤로 1 표준편차 범위 이내에 있음
- 경험적인 규칙을 적용하기 위한 가정
    - 평균 추청 오차가 0
        - 높게 예측할 가능성과 낮게 예측할 가능성이 같아야 함
        - 이런 류의 실험과 시뮬레이션에선 타당한 가정
        - 오차에 편향이 없다는 가정
    - 오차의 분포가 정규분포
        - 가우스 분포, 정규분포
    - 이 두 가정하에 경험적 규칙은 항상 유효
    
### 확률분포
- 확률 분포 : 확률 변수가 서로 다른 값을 가지는 상대적 빈도를 나타내는 개념
- 확률 변수
    - 이산 확률 변수
        - 유한 집합의 값들을 가짐
        - 동전을 던지면 앞면과 뒷면이란 2개의 값만 나옴
    - 연속 확률 변수
        - 확률밀도함수 (PDF)를 사용
        - 두 값 사이 어딘가에 존재할 확률을 알려줌
    
        
            
            
            
            




































