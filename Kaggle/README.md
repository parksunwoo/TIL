Today I Learned

## 범주형 변수에 대한 피쳐 엔지니어링
- Binarization과 Dummy encoding의 차이는?
- Dummy encoding과 One-hot-encoding의 차이는?
이진화는 모든 엔티티의 기능을 이진수 벡터로 변환하여 분류 알고리즘을 보다 효율적으로 만드는 프로세스이다. 간단한 예제에서 이미지의 그레이 스케일을 0-255 스펙트럼에서 0-1 스펙트럼으로 변환하는 것이 이진화이다. 

범주형 변수를 표현하는 데 가장 널리 쓰이는 방법은 원-핫-인코딩 (one-hot-encoding) 이다. 이를 원-아웃-오브-엔 인코딩(one-out-of-N encoding) 혹은 가변수(dummy variable) 라고도 한다. 가변수는 범주형 변수를 0 또는 1 값을 가진 하나 이상의 새로운 특성으로 바꾼 것이다. 0과 1로 표현된 변수는 선형 이진 분류 공식에 (그리고 scikit-learn에 있는 다른 모든 모델에) 적용할 수 있어서, 다음과 같이 개수에 상관없이 범주마다 하나의 특성으로 표현한다. 
예를 들면 colorName 특성에 “Black”, “Brown”, “Golden”, “Yellow” 가 있을 때 이 네 가지 값을 인코딩하기 위해 네 개의 새로운 특성 “Black”, “Brown”, “Golden”, “Yellow” 을 만든다. 어떤 애완동물의 colorName 값에 해당하는 특성은 1이 되고 나머지 세 특성은 0이 된다. 즉 데이터 포인트마다 정확히 네 개의 새로운 특성 중 하나는 1이 된다. 그래서 원-핫 또는 원-아웃 오브-엔 인코딩이라고 한다.

우리가 사용하는 원-핫 인코딩은 통계학에서 사용하는 더미 코딩(dummy coding)과 비슷하지만 완전히 같지는 않다. 간편하게 하려고 각 범주를 각기 다른 이진 특성으로 바꾸었다. 통계학에서는 k개의 값을 가진 범주형 특성을 k-1 개의 특성으로 변환하는 것이 일반적. (마지막 범주는 모든 열이 0으로 표현) 이렇게 하는 이유는 분석의 편리성 때문. ( 데이터 행렬의 랭크 부족 현상을 피하기 위해서이다)
예를 들면 네 개의 범주를 네 개의 특성으로 인코딩하면 맨 마지막 특성은 앞의 세 특성을 참조해서 예측할 수 있다. 이렇게 한 열이 다른 열에 의존적이거나 열의 값이 모두 0인 경우를 열 랭크 부족이라 하며, 행렬 분해 방식에 따라 문제가 될 수 있다. 

- Feature hashing은 어떨 때 유용하게 쓸 수 있는가?



   
  



























